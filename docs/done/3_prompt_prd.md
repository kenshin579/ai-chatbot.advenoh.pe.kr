# 프롬프트 개선 PRD: 답변 품질 향상

## 1. 배경

현재 챗봇은 블로그 원문(마크다운)을 거의 그대로 추출하여 나열하는 방식으로 답변한다.
사용자가 질문을 하면 "관련 블로그 글의 내용을 정리해서 보여주는" 느낌이지, "질문에 대해 대화형으로 설명해주는" 느낌이 아니다.

### 현재 답변 예시 (문제)

**질문**: "Claude Code Skill에 대해서 알려줘"

**현재 답변** (요약):
```
### Skill 개념
- **자동 로딩**: Skill은 Claude가 자동으로 감지하여 로드하는 지식 패키지입니다...
- **수동 호출 가능**: 사용자가 직접 `/skill-name`으로 호출할 수 있으며...
- **점진적 로딩**: 메타데이터를 먼저 스캔하고...

### 저장 위치
- 글로벌: `~/.claude/skills/`
- 프로젝트 전용: `.claude/skills/`

### Skill과 CLAUDE.md의 차이
- **로딩 시점**: CLAUDE.md는 대화 시작 시 항상 로드되지만...
```

→ 블로그 글의 마크다운 구조를 그대로 옮긴 형태. 답변이라기보다 **문서 발췌**에 가깝다.

### 기대하는 답변 예시 (목표)

```
Claude Code의 Skill은 특정 작업에 대한 전문 지식을 패키지로 만든 기능이에요.

핵심 특징을 설명하면, Skill은 사용자가 직접 호출하지 않아도 Claude가 현재 작업을
분석해서 관련 Skill을 자동으로 활성화합니다. 물론 `/skill-name` 형태로 직접 호출도
가능해요.

기존 CLAUDE.md와의 가장 큰 차이는 로딩 방식인데요:
- CLAUDE.md: 대화 시작 시 항상 로드 → 항상 토큰 소비
- Skill: 관련 작업 감지 시에만 로드 → 필요할 때만 토큰 소비

저장 위치는 글로벌(`~/.claude/skills/`)과 프로젝트 전용(`.claude/skills/`)
두 곳에 둘 수 있어요.

참고 글:
- Claude Code 확장 기능 완벽 가이드: Command, Skill, Subagent
```

→ 질문자에게 **설명하듯** 자연스러운 대화체. 핵심을 자기 말로 재구성.

## 2. 원인 분석

### 2.1 시스템 프롬프트 문제 (`templates.py`)

현재 프롬프트:
```
당신은 블로그 콘텐츠 전문 Q&A 어시스턴트입니다.
주어진 블로그 글 내용을 기반으로 사용자 질문에 정확하고 유용하게 답변합니다.
```

문제점:
- "블로그 원문을 그대로 나열하지 말 것"이라는 지시가 없음
- "자신의 말로 재구성하여 답변하라"는 지시가 없음
- "구조화된 답변" 규칙이 원문 마크다운 구조를 그대로 복사하게 유도
- "근거 기반" 규칙이 원문 인용 위주로 해석됨

### 2.2 raw 마크다운 컨텍스트 (`document_loader.py:79`)

```python
documents.append(Document(page_content=body, metadata=doc_metadata))
```

- YAML frontmatter만 제거하고 나머지 마크다운(`## 헤더`, `**볼드**`, `<img>` 태그, 코드블록 등)이 그대로 컨텍스트에 전달됨
- LLM이 마크다운 포맷팅을 보고 그대로 재현하는 경향

### 2.3 temperature 관련 분석

현재 설정:
```python
llm = ChatOpenAI(model=model, temperature=0)
```

**temperature를 올리면 요약식 답변이 나올까?**

결론: **아니다. temperature는 이 문제의 해결책이 아니다.**

- **temperature가 제어하는 것**: 다음 토큰 선택의 랜덤성(확률 분포). "어떤 단어를 선택할지"를 제어할 뿐, "어떤 방식으로 답변할지"(요약 vs 인용)는 제어하지 않는다.
- **temperature를 올렸을 때 일어나는 일**: 약간 다른 단어 선택이 될 뿐, 원문을 요약하거나 대화체로 바꾸라는 지시가 되지 않는다.
- **RAG에서 temperature를 올리면 생기는 위험**:
  - hallucination 증가 (컨텍스트에 없는 내용을 지어냄)
  - 사실적 정확도 저하
  - 같은 질문에 다른 답변 → 신뢰도 하락
  - instruction-following 능력 저하 (arXiv 연구 결과)

**RAG best practice의 temperature 권장값**:

| 용도 | 권장 temperature |
|---|---|
| RAG 팩트 기반 Q&A | 0.0 ~ 0.3 |
| RAG 대화형 스타일 | 0.0 ~ 0.3 (프롬프트로 스타일 제어) |
| 일반 챗봇 (비RAG) | 0.5 ~ 0.7 |
| 창작/크리에이티브 | 0.8 ~ 1.2 |

→ **원문 복사 문제는 프롬프트 문제이지 temperature 문제가 아니다.** temperature는 현재 0을 유지한다.

## 3. 모델 추천

현재 사용 중: `gpt-4o-mini` ($0.15/$0.60 per 1M tokens)

### OpenAI 모델 가격 비교 (2026년 2월 기준)

**경량 모델 (RAG 챗봇 후보)**:

| 모델 | Input (1M) | Cached Input | Output (1M) | 컨텍스트 | 출시 |
|---|---:|---:|---:|---|---|
| **gpt-5-nano** | $0.05 | $0.005 | $0.40 | 400K | 2025.10 |
| **gpt-4.1-nano** | $0.10 | $0.025 | $0.40 | 1M | 2025.04 |
| gpt-4o-mini (현재) | $0.15 | $0.075 | $0.60 | 128K | 2024.07 |
| gpt-5-mini | $0.25 | $0.025 | $2.00 | 400K | 2025.10 |
| gpt-4.1-mini | $0.40 | $0.10 | $1.60 | 1M | 2025.04 |

**중대형 모델 (참고)**:

| 모델 | Input (1M) | Cached Input | Output (1M) | 컨텍스트 | 출시 |
|---|---:|---:|---:|---|---|
| gpt-5 | $1.25 | $0.125 | $10.00 | 400K | 2025.10 |
| gpt-5.1 | $1.25 | $0.125 | $10.00 | 400K | 2025.11 |
| gpt-5.2 | $1.75 | $0.175 | $14.00 | 400K | 2025.12 |
| gpt-4.1 | $2.00 | $0.50 | $8.00 | 1M | 2025.04 |
| gpt-4o | $2.50 | $1.25 | $10.00 | 128K | 2024.05 |
| gpt-5-pro | $15.00 | - | $120.00 | 400K | 2025.10 |
| gpt-5.2-pro | $21.00 | - | $168.00 | 400K | 2025.12 |

> 참고: [OpenAI Pricing](https://platform.openai.com/docs/pricing)

### 추천: `gpt-4.1-nano`

| 기준 | gpt-4o-mini (현재) | gpt-4.1-nano (추천) | gpt-5-nano (대안) |
|---|---|---|---|
| **비용 (input/output)** | $0.15 / $0.60 | $0.10 / $0.40 | **$0.05** / $0.40 |
| **컨텍스트 윈도우** | 128K | **1M** | 400K |
| **속도** | 빠름 | 빠름 | 빠름 |
| **안정성** | 검증됨 | 검증됨 | 비교적 최신 |
| **월 예상 비용** (100회/일) | ~$1.08 | ~$0.72 | ~$0.63 |

**1순위 추천: `gpt-4.1-nano`**
1. gpt-4o-mini 대비 **33% 저렴**하면서 품질 차이는 미미
2. **1M 컨텍스트 윈도우**로 RAG에서 더 많은 문서를 한 번에 전달 가능
3. 개인 블로그 챗봇 수준에서 월 **$1 미만** 운영 가능
4. RAG 시나리오에서 gpt-4o-mini보다 오히려 더 정확한 답변을 보인다는 벤치마크 결과 존재
5. 출시 후 충분히 검증된 모델

**2순위 대안: `gpt-5-nano`**
1. input 가격이 $0.05로 **gpt-4.1-nano 대비 50% 저렴** (가장 저렴한 모델)
2. 다만 2025.10 출시로 비교적 최신이라 RAG 품질 벤치마크가 아직 제한적
3. 컨텍스트 400K는 RAG 용도로 충분하지만 gpt-4.1-nano의 1M보다 작음
4. gpt-4.1-nano로 먼저 검증 후, gpt-5-nano로 전환 테스트 권장

## 4. 요구사항

### 4.1 시스템 프롬프트 개선 (핵심)

**수정 파일**: `backend/app/prompts/templates.py`

추가/변경할 규칙:

| 규칙 | 설명 |
|---|---|
| **대화형 답변** | 블로그 원문을 그대로 나열하지 말고, 질문자에게 설명하듯 자연스러운 대화체로 답변할 것 |
| **자기 말로 재구성** | 컨텍스트 내용을 자신의 말로 재구성하여 전달. 원문 복붙 금지 |
| **질문 중심 답변** | 컨텍스트 전체를 나열하지 말고, 질문에 직접 관련된 핵심만 선별하여 답변 |
| **코드는 선별적** | 질문과 직접 관련된 코드만 포함. 원문의 모든 코드를 나열하지 않음 |
| **마크다운 헤더 남용 금지** | 원문의 `##`, `###` 구조를 그대로 복사하지 않음. 필요 시 볼드나 리스트 사용 |

### 4.2 모델 변경

**수정 파일**: `backend/app/config.py` (또는 환경변수)

- `gpt-4o-mini` → `gpt-4.1-nano` 로 변경

### 4.3 temperature 유지

**변경 없음**: `temperature=0` 유지

- 요약/대화체 답변은 **프롬프트 개선**으로 해결
- temperature를 올리면 hallucination 위험만 증가
- RAG best practice에서도 0.0~0.3 권장

### 4.4 수정 범위 요약

| 파일 | 변경 내용 | 우선순위 |
|---|---|---|
| `backend/app/prompts/templates.py` | 시스템 프롬프트 답변 스타일 규칙 추가 | **필수** |
| `backend/app/config.py` (또는 환경변수) | 모델 gpt-4o-mini → gpt-4.1-nano | **필수** |
| `backend/app/rag/chain.py` | temperature 변경 없음 (0 유지) | 변경 없음 |

> document_loader의 raw 마크다운 전달 방식은 현 단계에서 변경하지 않는다.
> 프롬프트 개선만으로 LLM이 마크다운을 적절히 해석하여 답변하도록 유도하는 것이 우선이다.
> 효과가 부족할 경우 후속 작업으로 마크다운 전처리를 검토한다.

## 5. 수용 기준

- [ ] 동일한 질문("Claude Code Skill에 대해서 알려줘")에 대해 원문 나열이 아닌 대화형 답변이 나오는지 확인
- [ ] 답변이 블로그 원문의 마크다운 헤더 구조(`### 제목`)를 그대로 복사하지 않는지 확인
- [ ] 컨텍스트에 없는 내용을 지어내지 않는지(hallucination) 확인
- [ ] 기존 기능(참고 글 출처 표시, 대화 히스토리 등)이 정상 동작하는지 확인
- [ ] gpt-4.1-nano 모델로 정상 동작하는지 확인
